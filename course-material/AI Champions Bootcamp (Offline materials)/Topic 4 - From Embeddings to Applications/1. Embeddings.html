<!DOCTYPE html>
<html><head>
    
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/tinycolor.js" async="" id="tinycolor-script"></script>
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/pixi.js" async="" id="pixi-script"></script>
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/minisearch.js" async="" id="minisearch-script"></script>
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/flowbite.min.js" class="" style="transition: opacity 0.5s ease-in-out"></script>
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/saved_resource.js" class="" style="transition: opacity 0.5s ease-in-out"></script>
    <script src="https://sp-soc-kh.github.io/ai-bootcamp-static/js/index.js" class="" style="transition: opacity 0.5s ease-in-out"></script>
    
    <link rel="alternate" href="https://abc-notes.data.tech.gov.sg/notes/lib/rss.xml" type="application/rss+xml" title="RSS Feed">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/flowbite.min.css" class="" style="transition: opacity 0.5s ease-in-out">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/full.css" type="text/css" class="" style="transition: opacity 0.5s ease-in-out">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/obsidian.css">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/theme.css">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/global-variable-styles.css">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/main-styles.css">
    <link rel="stylesheet" href="https://sp-soc-kh.github.io/ai-bootcamp-static/css/fix-style.css">
  </head><body style="
      color: rgb(32, 33, 34);
      font-family: verdana, sans-serif;
      font-size: 12px;
    " class="publish css-settings-manager theme-light show-inline-title show-ribbon floating-sidebars is-tablet"><div class="webpage-container workspace">
<div class="document-container markdown-reading-view">
<div class="markdown-preview-view markdown-rendered is-readable-line-width">
<pre class="frontmatter language-yaml" style="display: none;" tabindex="0"><code class="language-yaml is-loaded"><span class="token key atrule">icon</span><span class="token punctuation">:</span> LiNotebook</code><button class="copy-code-button">Copy</button></pre>
<div class="markdown-preview-sizer markdown-preview-section">
<div id="webpage-icon">
<p dir="auto"><span class="cm-iconize-icon" aria-label="LiNotebook" data-icon="LiNotebook" aria-hidden="true" style="display: inline-flex; transform: translateY(13%);"><svg xmlns="http://www.w3.org/2000/svg" width="16px" height="16px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                      <path d="M2 6h4"></path>
                      <path d="M2 10h4"></path>
                      <path d="M2 14h4"></path>
                      <path d="M2 18h4"></path>
                      <rect width="16" height="20" x="4" y="2" rx="2"></rect>
                      <path d="M16 2v20"></path></svg></span></p>
</div>
<ol start="1">
<li dir="auto" class="page-title heading fix-heading" id="Title: Embeddings">Title: Embeddings</li>
</ol>
<h1 class="page-title heading inline-title" id="Title: Embeddings"></h1>
<div class="heading-wrapper">
<ul class="steps">
<li class="step step-success" data-content="üìí" dir="auto">Embeddings</li>
<li class="step" data-content="üìí" dir="auto">Handling Embeddings</li>
<li class="step" data-content="üîß" dir="auto">Applying Embeddings</li>
<li class="step" data-content="üîß" dir="auto">Retrieval Augmented Generation (RAG)</li>
<li class="step" data-content="üîß" dir="auto">Hands-on Walkthrough and Tasks</li>
</ul>
<div class="heading-children">
<div>
<p dir="auto"></p>
<div src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240421130125974.png" class="internal-embed media-embed image-embed is-loaded"><img src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240421130125974.png"></div>
<p dir="auto"></p>
</div>
<div>
<div class="block-language-toc dynamic-toc">
<h1 data-heading="Table of Contents" dir="auto" class="heading" id="Table_of_Contents">Table of Contents</h1>
<ul>
<li dir="auto"><a data-href="#What is Embeddings" href="#What_is_Embeddings" class="internal-link" target="_self" rel="noopener">What is Embeddings</a></li>
<li dir="auto"><a data-href="#Visualize Embeddings" href="#Visualize_Embeddings" class="internal-link" target="_self" rel="noopener">Visualize Embeddings</a></li>
<li dir="auto"><a data-href="#Why are Embeddings Important" href="#Why_are_Embeddings_Important" class="internal-link" target="_self" rel="noopener">Why are Embeddings Important</a></li>
<li dir="auto"><a data-href="#Embeddings Are Evolving" href="#Embeddings_Are_Evolving" class="internal-link" target="_self" rel="noopener">Embeddings Are Evolving</a></li>
</ul>
</div>
</div>
<div><hr></div>
<div><hr></div>
<div></div>
</div>
</div>
<div class="heading-wrapper">
<h1 data-heading="What is Embeddings" dir="auto" class="heading" id="What_is_Embeddings">What is Embeddings</h1>
<div class="heading-children">
<div>
<ul>
<li data-line="0" dir="auto">
<p>‚ú¶ Embeddings are a type of representation that bridges the human understanding of language to that of a machine.</p>
<ul>
<li data-line="1" dir="auto">In the context of Large Language Models (LLMs), to be specific, we are dealing with <strong>text embeddings.</strong></li>
<li data-line="2" dir="auto">There are other types of embeddings, such as image, audio, and video embeddings.</li>
<li data-line="3" dir="auto">Embeddings are a powerful technique in machine learning that allows us to represent data in a lower-dimensional space while preserving its semantic meaning.</li>
<li data-line="4" dir="auto">This approach has revolutionized various fields, including natural language processing (NLP), computer vision, and more.</li>
</ul>
</li>
<li data-line="6" dir="auto">
<p>‚ú¶ They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.</p>
<ul>
<li data-line="7" dir="auto">
<p>Large language models like GPT-4, Gemini, or BERT use word embeddings as the first layer of the model. We know, BERT is not that "large" compared to the other two, but it's still considered a significant advancement in natural language processing.</p>
</li>
<li data-line="9" dir="auto">
<p>These models convert each word into a dense vector and feed it into the model. The models then use these vectors to predict the next word in a sentence (in the case of GPT-4) or to understand the context of a word (in the case of BERT).</p>
</li>
<li data-line="11" dir="auto">
<p>These models are trained on a large corpus of text, so they learn the semantic meaning of words. For example, the word ‚Äúking‚Äù is closer in this space to ‚Äúqueen‚Äù than it is to ‚Äúapple‚Äù.</p>
</li>
<li data-line="13" dir="auto">
<p>They are <strong>representations of text in a N-dimensional space</strong> where words that have the same meaning have a similar representation.</p>
<ul>
<li data-line="14" dir="auto">The text is translated into numbers, specifically into vectors.</li>
<li data-line="15" dir="auto">That's why we will often see some articles describe embeddings as <strong>vectors</strong> too.</li>
<li data-line="16" dir="auto">Essential, text embeddings is a vector (i.e., a list) of floating point numbers.</li>
<li data-line="17" dir="auto">In other words, it represents words in <strong>a coordinate system where related words, based on a corpus of relationships, are placed closer together.</strong></li>
</ul>
</li>
<li data-line="19" dir="auto">
<p>The number of values in a text embedding ‚Äî known as its ‚Äúdimension‚Äù ‚Äî depends on the embedding technique (the process of producing the vector), as well as how much information you want it to convey.</p>
</li>
<li data-line="21" dir="auto">
<p>The embeddings below shows a vector with 8 dimensions.</p>
<div src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240420171232453.png" class="internal-embed media-embed image-embed is-loaded"><img src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240420171232453.png"></div>
<p></p>
</li>
<li data-line="25" dir="auto">
<p>Table below show the common models with the dimensions of their embeddings</p>
</li>
</ul>
</li>
</ul>
</div>
<div dir="ltr" style="overflow-x: auto;">
<table>
<thead>
<tr>
<th dir="ltr">Model</th>
<th dir="ltr">Embedding Dimension</th>
<th dir="ltr">Max Input Tokens</th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">BERT-Base</td>
<td dir="auto">768</td>
<td dir="auto">512</td>
</tr>
<tr>
<td dir="ltr">BERT-Large</td>
<td dir="auto">1024</td>
<td dir="auto">512</td>
</tr>
<tr>
<td dir="ltr">GPT-2</td>
<td dir="auto">768</td>
<td dir="auto">1024</td>
</tr>
<tr>
<td dir="ltr">GPT-3</td>
<td dir="auto">768</td>
<td dir="auto">2048</td>
</tr>
<tr>
<td dir="ltr">RoBERTa-Base</td>
<td dir="auto">768</td>
<td dir="auto">512</td>
</tr>
<tr>
<td dir="ltr">RoBERTa-Large</td>
<td dir="auto">1024</td>
<td dir="auto">512</td>
</tr>
<tr>
<td dir="ltr">DistilBERT</td>
<td dir="auto">768</td>
<td dir="auto">512</td>
</tr>
<tr>
<td dir="ltr">OpenAI text-embedding-3-small</td>
<td dir="auto">1536</td>
<td dir="auto">8191</td>
</tr>
<tr>
<td dir="ltr">OpenAI text-embedding-3-large</td>
<td dir="auto">3072</td>
<td dir="auto">8191</td>
</tr>
</tbody>
</table>
</div>
<div><hr></div>
<div><hr></div>
<div></div>
</div>
</div>
<div class="heading-wrapper">
<h1 data-heading="Visualize Embeddings" dir="auto" class="heading" id="Visualize_Embeddings">Visualize Embeddings</h1>
<div class="heading-children">
<div>
<ul>
<li data-line="0" dir="auto">‚ú¶ Let‚Äôs try to visualize the concept. Imagine that we have a collection of sentences that we‚Äôve turned into vectors, using a dense embedding technique.
<ul>
<li data-line="1" dir="auto">If we simplify these vectors with hundreds of dimensions to just two dimensions, which we can plot them on a similarly designed two-dimensional grid.</li>
<li data-line="2" dir="auto">For example, consider these seven pieces of text:</li>
</ul>
</li>
</ul>
</div>
<div>
<pre class="line-numbers d2l-code"><code class="language-python">in_1 = "Flamingo spotted at the bird park"

in_2 = "Sea otter seen playing at the marine park"

in_3 = "Baby panda born at the city zoo"

in_4 = "Python developers prefer snake_case for variable naming"

in_5 = "New JavaScript framework aims to simplify coding"

in_6 = "C++ developers appreciate the power of OOP"

in_7 = "Java is a popular choice for enterprise applications"


list_of_input_texts = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]</code></pre>
‚ú¶ Each of the 7 texts will converted into a vector (again, you can understand vector as list for our purpose). The diagram below shows the first text is converted into a vector. Imagine each of the 7 texts has it own vector that has 1536 numerical values. Here we assume we are using OpenAI's <code>text-embedding-3-small</code></div>
<div>
<div src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240421151447194.png" class="internal-embed media-embed image-embed is-loaded"><img src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/img-20240421151447194.png"></div>
<p dir="auto"></p>
</div>
<code>
</code>
<div></div>
<code>
</code>
<div>
<ul>
<li></li>
<li data-line="0" dir="auto">‚ú¶ The diagram below show graph after we simplified the 7 vectors down to 2 dimensions and plot them onto the x and y axes.
<ul>
<li></li>
<li data-line="1" dir="auto"><strong>Observe the distances</strong> between the different texts</li>
<li></li>
<li data-line="2" dir="auto">Although the text that starts with "<em>Python developers prefer snake_case</em>", contains two animals, the embedding is further away from the three data points that are truly talking about real animals</li>
<li></li>
<li data-line="3" dir="auto">It is closer to the other two data points that are about programming/coding</li>
<li></li>
</ul>
</li>
<li></li>
</ul>
</div>
<code>
</code>
<div>
<p dir="auto"><img src="https://sp-soc-kh.github.io/ai-bootcamp-static/images/embeddings_distance.png" referrerpolicy="no-referrer"></p>
</div>
<code>
</code>
<div>
<div data-callout-metadata="" data-callout-fold="" data-callout="info" class="callout drop-shadow">
<div class="callout-title" dir="auto">
<div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-info">
                          <circle cx="12" cy="12" r="10"></circle>
                          <path d="M12 16v-4"></path>
                          <path d="M12 8h.01"></path>
                        </svg></div>
<div class="callout-title-inner">We will discuss how are we convert the 1536 dimensions into just 2 dimensions in the later part of Topic 4 <a class="internal-link" data-href="https://ichatspedu.sharepoint.com.2.%20Handling%20Embeddings.md#Visualizing Embeddings" href="https://abc-notes.data.tech.gov.sg/notes/topic-4-from-embeddings-to-applications/2.-handling-embeddings.html#Visualizing_Embeddings" target="_self" rel="noopener">Visualizing Embeddings</a></div>
</div>
</div>
</div>
<code>
</code>
<div><hr></div>
<code>
</code>
<div><hr></div>
<code>
</code>
<div></div>
<code>
</code></div>
<code>
</code></div>
<code>
</code>
<div class="heading-wrapper">
<h1 data-heading="Why are Embeddings Important" dir="auto" class="heading" id="Why_are_Embeddings_Important">Why are Embeddings Important</h1>
<div class="heading-children">
<div>
<ul>
<li></li>
<li data-line="0" dir="auto">
<p>‚ú¶ The straightforward reason is that they can <strong>reduce</strong> data dimensionality and address the primary issue: the necessity for <strong>speed</strong>.</p>
<ul>
<li></li>
<li data-line="2" dir="auto">As AI‚Äôs capabilities continue to grow, scaling automation can face <strong>speed</strong> and <strong>cost</strong> constraints. This is where the recent rise in interest in Embeddings becomes significant.</li>
<li></li>
<li data-line="4" dir="auto">The main application of these technologies is the <strong>demand for speed</strong>, especially when processing large volumes of text data.</li>
<li></li>
<li data-line="6" dir="auto">This is particularly pertinent for large language models like the GPT series, whether they are closed or open-sourced, where the efficient processing of enormous amounts of text is vital.</li>
<li></li>
<li data-line="8" dir="auto">Embeddings serve as engineering tools to tackle the challenge of processing large-scale text <strong>swiftly</strong> and <strong>cost-effectively</strong>.</li>
<li></li>
</ul>
</li>
<li></li>
</ul>
</div>
<div><hr></div>
<div>
<ul>
<li></li>
<li data-line="0" dir="auto">
<p>‚ú¶ The initial phase of any Large Language Model (LLM) training is the most crucial: the neural network is constructed from a vast amount of data with an extensive number of features (let‚Äôs refer to them as details).</p>
<ul>
<li></li>
<li data-line="2" dir="auto">Language, of which the text is representing, contains many dimensions that are hard to specify or structurally quantify, including sentiment, grammar, meaning, and objects, just to mention a few.</li>
<li></li>
<li data-line="4" dir="auto">The more <strong>dimensions</strong> there are, the more challenging it is for computers to analyze and learn from the data. This is where <strong>embeddings</strong> come in.</li>
<li></li>
<li data-line="6" dir="auto">Data scientists employ embeddings to depict high-dimensional data in a low-dimensional space.</li>
<li></li>
<li data-line="8" dir="auto">Think of embeddings as summaries.
<ul>
<li></li>
<li data-line="9" dir="auto">They take high-dimensional data and condense it into a smaller, more manageable form, like picking out the key points from a long text.</li>
<li></li>
<li data-line="11" dir="auto">This makes it easier and faster for AI models to process and understand the information. Just like summarizing a book saves you time and effort, embeddings help AI models work more efficiently.</li>
<li></li>
<li data-line="13" dir="auto">Reducing the number of features while still capturing important patterns and relationships is the job of the Embeddings.</li>
<li></li>
<li data-line="15" dir="auto">They allow AI models to learn and make predictions faster and with less computing power.</li>
<li></li>
</ul>
</li>
<li></li>
</ul>
</li>
<li></li>
</ul>
</div>
<div><hr></div>
<div><hr></div>
<div></div>
</div>
</div>
<code>
</code>
<div class="heading-wrapper">
<h1 data-heading="Embeddings Are Evolving" dir="auto" class="heading" id="Embeddings_Are_Evolving">Embeddings Are Evolving</h1>
<div class="heading-children">
<div>
<p dir="auto">Embedding models have been used for a long time, primarily for training other LLMs or ML models.</p>
</div>
<div>
<p dir="auto">The introduction of Retrieval Augmented Generation (RAG) and subsequently of Vector Store Databases has shed new light on these models.</p>
</div>
<div>
<p dir="auto">They have a few common issues:</p>
</div>
<div>
<ol>
<li></li>
<li data-line="0" dir="auto">They have a context length limit, just like Large Language Models.</li>
<li></li>
<li data-line="1" dir="auto">They usually excel at only one language (English).</li>
<li></li>
<li data-line="2" dir="auto">High-dimensional vectors are typically required for optimal results.</li>
<li></li>
<li data-line="3" dir="auto">They are usually trained for a specific task (text, image, or audio).</li>
<li></li>
</ol>
</div>
<div>
<p dir="auto">As research progressed, new state-of-the-art (text) embedding models began producing embeddings with increasingly higher output dimensions, meaning each input text is represented using more values. While this improves performance, it comes at the cost of efficiency and speed. Researchers were therefore motivated to create embedding models whose embeddings could be reasonably reduced in size without significantly sacrificing performance.</p>
</div>
<div class="mod-footer"></div>
</div>
</div>
<code>
</code></div>
<code>
</code></div>
<code>
</code></div>
<code>
</code></div></body></html>